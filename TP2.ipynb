{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c345f75",
   "metadata": {},
   "source": [
    "# Trabalho prático 2\n",
    "### Processamento de Sinais Multimédia\n",
    "####  Alunos: Diana Oliveira 52651; Beatriz Jesus 52749; Guilherme Cavalcanti 53077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560bbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal as ss\n",
    "import scipy.io.wavfile as wav \n",
    "from IPython.display import Audio, display \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81371bd6",
   "metadata": {},
   "source": [
    "##### Exercício 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8772360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Parâmetros Globais ---------\n",
    "Fs = 48000  # Frequência de amostragem\n",
    "temperatura = 20  # Temperatura em graus Celsius\n",
    "recetorPos = (10,4) # Coordenadas do recetor (x,y) em metros\n",
    "fonte1 = (10,6) # Coordenadas da fonte (x,y) em metros\n",
    "fonte2 = (3,2) \n",
    "fonte3 = (17,8) \n",
    "fonte4 = (13,3) \n",
    "fonte5 = (6,9) \n",
    "fonte6 = (8,5) \n",
    "fonte7 = (12,7)\n",
    "\n",
    "#S1 = (8,13) # reflexão da parede horizontal absorção=0.5\n",
    "#S2 = (-7,7) # reflexão da parede vertical absorção=0.3\n",
    "a = [0.5, 0.3]  # Coeficientes de absorção das paredes [parede vertical, parede horizontal]\n",
    "c = 331.5 * np.sqrt(1 + temperatura/273) # Velocidade do som no ar em m/s \n",
    "\n",
    "# --------- MUTES ---------\n",
    "#campo_direto_mute = False\n",
    "mute1 = False\n",
    "\n",
    "\n",
    "#Configurações Gerais\n",
    "# --------- Converter Aúdio ---------\n",
    "def audio_convertido(filename): # Adicionei Fs como argumento ou certifique-se que está definido globalmente\n",
    "    fs_audio_org, audio_org = wav.read(filename) \n",
    "    audio_org = audio_org.astype(np.float32) # Converter para float32 \n",
    "    max_val = np.max(np.abs(audio_org)) # Normalizar o áudio\n",
    "    if max_val > 0: # Evitar divisão por zero\n",
    "        audio_org /= max_val\n",
    "    \n",
    "    num_samples_new = int(len(audio_org) * Fs / fs_audio_org) # Calcular o número de amostras para o novo Fs\n",
    "    audio_resampled = ss.resample(audio_org, num_samples_new) # Reamostrar o áudio para o novo Fs\n",
    "    \n",
    "    MAX_INT16 = 2**15 - 1 # Valor máximo para int16\n",
    "    audio_resampled_scaled = audio_resampled * MAX_INT16 # Escalar para o intervalo de int16\n",
    "    audio_resampled_clipped = np.clip(audio_resampled_scaled, -MAX_INT16, MAX_INT16) # Clipping para evitar overflow\n",
    "    audio_final = audio_resampled_clipped.astype(np.int16) # Converter para int16\n",
    "    \n",
    "    return audio_final\n",
    "\n",
    "# O aúdio utilizado já tem 16 bits mas fs=44100 Hz --> Tem que converter para Fs=48000 Hz\n",
    "audio_resampled = audio_convertido(\"Borderline_UnmasteredWAV.wav\")\n",
    "wav.write(\"AudioConvertido.wav\", Fs, audio_resampled)\n",
    "\n",
    "# Os aúdios têm 44000hz e 24 bits --> converter para 48000hz e 16 bits\n",
    "audio1_resampled = audio_convertido(\"instrumentos/01_Kick.wav\")\n",
    "wav.write(\"instrumentos/01_Kick_Convertido.wav\", Fs, audio1_resampled)\n",
    "audio2_resampled = audio_convertido(\"instrumentos/02_Snare.wav\")\n",
    "wav.write(\"instrumentos/02_Snare_Convertido.wav\", Fs, audio2_resampled)\n",
    "audio3_resampled = audio_convertido(\"instrumentos/03_Overheads.wav\")\n",
    "wav.write(\"instrumentos/03_Overheads_Convertido.wav\", Fs, audio3_resampled)\n",
    "audio4_resampled = audio_convertido(\"instrumentos/04_Percussion.wav\")\n",
    "wav.write(\"instrumentos/04_Percussion_Convertido.wav\", Fs, audio4_resampled)\n",
    "audio5_resampled = audio_convertido(\"instrumentos/05_Bass.wav\")\n",
    "wav.write(\"instrumentos/05_Bass_Convertido.wav\", Fs, audio5_resampled)\n",
    "audio6_resampled = audio_convertido(\"instrumentos/06_Gtr.wav\")\n",
    "wav.write(\"instrumentos/06_Gtr_Convertido.wav\", Fs, audio6_resampled)\n",
    "audio7_resampled = audio_convertido(\"instrumentos/07_LeadVox.wav\")\n",
    "wav.write(\"instrumentos/07_LeadVox_Convertido.wav\", Fs, audio7_resampled)\n",
    "\n",
    "# --------- Ler Aúdio Convertido  ---------\n",
    "_ , audio = wav.read(\"AudioConvertido.wav\")\n",
    "fs_audio1, audio1 = wav.read(\"instrumentos/01_Kick_Convertido.wav\")\n",
    "fs_audio2, audio2 = wav.read(\"instrumentos/02_Snare_Convertido.wav\")\n",
    "fs_audio3, audio3 = wav.read(\"instrumentos/03_Overheads_Convertido.wav\")\n",
    "fs_audio4, audio4 = wav.read(\"instrumentos/04_Percussion_Convertido.wav\")\n",
    "fs_audio5, audio5 = wav.read(\"instrumentos/05_Bass_Convertido.wav\")\n",
    "fs_audio6, audio6 = wav.read(\"instrumentos/06_Gtr_Convertido.wav\")\n",
    "fs_audio7, audio7 = wav.read(\"instrumentos/07_LeadVox_Convertido.wav\")\n",
    "\n",
    "\n",
    "#calcular distancia das reflexoes\n",
    "def distancia_reflexao(posFonte, parede): # pq as paredes sao os eixos do x e y\n",
    "    if parede == 'horizontal':\n",
    "        fonte_refletida = (posFonte[0], -posFonte[1])\n",
    "    elif parede == 'vertical':\n",
    "        fonte_refletida = (-posFonte[0], posFonte[1])\n",
    "\n",
    "    distancia = np.sqrt((recetorPos[0] - fonte_refletida[0])**2 + (recetorPos[1] - fonte_refletida[1])**2)\n",
    "    return distancia\n",
    "\n",
    "\n",
    "# --------- Reverberação ---------\n",
    "Comb_m = [int(0.03*Fs), int(0.05*Fs), int(0.07*Fs), int(0.09*Fs)]   # atraso do comb filters\n",
    "AllPass_m = [int(0.005*Fs), int(0.0017*Fs)]  # atraso dos allpass filters de\n",
    "\n",
    "\n",
    "def FBCF(alpha, Dc):\n",
    "    b = np.zeros(Dc + 1); b[-1] = 1 \n",
    "    a = np.zeros(Dc + 1); a[0] = 1; a[-1] = -alpha #ganho\n",
    "    return b, a \n",
    "\n",
    "def AllPass(g, Da):\n",
    "    b = np.zeros(Da + 1); b[0] = -g; b[-1] = 1 \n",
    "    a = np.zeros(Da + 1); a[0] = 1; a[-1] = -g \n",
    "    return b, a\n",
    "\n",
    "\n",
    "def getganho(RT60, m):\n",
    "    ganho = 10**((-3 * m* (1/Fs)) / (RT60)) # 20*log10(g) / (m*T) = -60 / Tr  => log10(g) = -3*m*T / Tr , onde tr é rt60 e o T é o peirodo de amostragem (1/Fs)(passar dominio de amotras para tempo)\n",
    "    return ganho\n",
    "\n",
    "\n",
    "def reverb(campo, RT60):\n",
    "    if RT60 == 0:\n",
    "        return np.zeros_like(campo)\n",
    "    sinal = np.zeros_like(campo)\n",
    "    for m in Comb_m:\n",
    "        ganho = getganho(RT60, m)\n",
    "        bks, aks = FBCF(ganho, m)\n",
    "        sinal += ss.lfilter(bks, aks, campo)\n",
    "\n",
    "    for m in AllPass_m:\n",
    "        bks, aks = AllPass(0.7, m)  \n",
    "        sinal = ss.lfilter(bks, aks, sinal)\n",
    "        \n",
    "    return sinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464150bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------(d) Campo total = Campo direto + Primeiras reflexões + Campo Reverberante ---------\n",
    "distancia_recetor_fonte = np.sqrt((np.abs(recetorPos[0])-np.abs(fonte1[0]))**2 + (np.abs(recetorPos[1])-np.abs(fonte1[1]))**2)  # Distância entre fonte e recetor\n",
    "distancia_recetor_S1 = distancia_reflexao(fonte1, 'horizontal')  # Distância entre recetor e S1\n",
    "distancia_recetor_S2 = distancia_reflexao(fonte1, 'vertical')  # Distância entre recetor e S2\n",
    "\n",
    "# --------- Campo Direto ---------\n",
    "t1 = distancia_recetor_fonte / c  # Tempo de atraso em segundos\n",
    "m1 = int(t1 * Fs)  # Número de amostras de atraso\n",
    "a1 = audio[:,0] * (1/distancia_recetor_fonte) # ganho (atenuação)\n",
    "\n",
    "# --------- 1º Reflexão ---------\n",
    "t2 = distancia_recetor_S1 / c  # Tempo de atraso em segundos\n",
    "m2 = int(t2 * Fs)  # Número de amostras de atraso\n",
    "a2 =  audio[:,0] * (1-a[0]) * (1/distancia_recetor_S1)  # ganho (coeficiente absorção * atenuação)\n",
    "\n",
    "# --------- 2º Reflexão ---------\n",
    "t3 = distancia_recetor_S2 / c  # Tempo de atraso em segundos\n",
    "m3 = int(t3 * Fs)  # Número de amostras de atraso\n",
    "a3 = audio[:,0] * (1-a[1]) * (1/distancia_recetor_S2) # ganho (coeficiente absorção * atenuação pela distância)\n",
    "\n",
    "\n",
    "# Aplicar o atraso a cada um dos audios\n",
    "atraso1 = np.zeros((m1))\n",
    "a1 = np.concatenate((atraso1, a1), axis=0)# ganho do campo direto\n",
    "\n",
    "atraso2 = np.zeros((m2))    \n",
    "a2 = np.concatenate((atraso2, a2), axis=0) # ganho da 1ª reflexão\n",
    "\n",
    "atraso3 = np.zeros((m3))\n",
    "a3 = np.concatenate((atraso3, a3), axis=0)# ganho da 2ª reflexão\n",
    "\n",
    "# Determinar o tamanho máximo\n",
    "max_len = max(len(a1), len(a2), len(a3))\n",
    "\n",
    "# Preencher zeros no final de cada array para igualar tamanhos\n",
    "a1 = np.pad(a1, (0, max_len - len(a1)), mode='constant')\n",
    "a2 = np.pad(a2, (0, max_len - len(a2)), mode='constant')\n",
    "a3 = np.pad(a3, (0, max_len - len(a3)), mode='constant')\n",
    "\n",
    "\n",
    "campo = a1 + a2 + a3 #campo direto, 1ª e 2ª reflexão\n",
    "reflexoes = a2 + a3 #só as primeiras reflexões              \n",
    "\n",
    "\n",
    "\n",
    "# --------- RT60 ---------\n",
    "\n",
    "# Aplicar a reverberação para diferentes valores de RT60\n",
    "campo0  = campo\n",
    "campo05 = reverb(reflexoes, 0.5)\n",
    "campo2  = reverb(reflexoes, 2)\n",
    "campo10 = reverb(reflexoes, 10)\n",
    "    \n",
    "\n",
    "# Normalizar os sinais\n",
    "campo_total_0 = campo0/np.max(np.abs(campo0))\n",
    "campo_total_05 = campo05/np.max(np.abs(campo05))\n",
    "campo_total_2 = campo2/np.max(np.abs(campo2))\n",
    "campo_total_10 = campo10/np.max(np.abs(campo10))\n",
    "\n",
    "\n",
    "# --------- Gravar e Reproduzir 10 segundos do Aúdio ---------\n",
    "filename_exercício1 = [\"Exercício1_RT60_0.wav\", \"Exercício1_RT60_0.5.wav\", \"Exercício1_RT60_2.wav\", \"Exercício1_RT60_10.wav\"]\n",
    "wav.write(filename_exercício1[0], Fs, campo_total_0.astype(np.int16))\n",
    "wav.write(filename_exercício1[1], Fs,  campo_total_05.astype(np.int16))\n",
    "wav.write(filename_exercício1[2], Fs,  campo_total_2.astype(np.int16))\n",
    "wav.write(filename_exercício1[3], Fs,  campo_total_10.astype(np.int16))\n",
    "\n",
    "print(\"Aúdio Original\")\n",
    "display(Audio(\"AudioConvertido.wav\", rate=Fs))\n",
    "print(\"RT60 = 0s\")\n",
    "display(Audio(campo_total_0[:10*Fs], rate=Fs))\n",
    "print(\"RT60 = 0.5s\")\n",
    "display(Audio(campo_total_05[:10*Fs], rate=Fs))\n",
    "print(\"RT60 = 2s\")\n",
    "display(Audio(campo_total_2[:10*Fs], rate=Fs))\n",
    "print(\"RT60 = 10s\")\n",
    "display(Audio(campo_total_10[:10*Fs], rate=Fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d2576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- (a) Campo Direto ---------\n",
    "t1 = distancia_recetor_fonte / c  # Tempo de atraso em segundos\n",
    "m1 = int(t1 * Fs)  # Número de amostras de atraso\n",
    "a1 = (1/distancia_recetor_fonte) # ganho (atenuação)\n",
    "# ABKS E BKS\n",
    "aks = [1]\n",
    "bks = np.zeros(m1 + 1)\n",
    "bks[m1] = a1\n",
    "campo = ss.lfilter(bks, aks, audio[:,0]) # Teve que ser mono para não dar erro\n",
    "\n",
    "\n",
    "display(Audio(campo[:10*Fs], rate=Fs))\n",
    "#plt.plot(campo)\n",
    "#plt.xlim(0, 3*Fs)\n",
    "t = np.arange(len(campo)) / Fs \n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(t, campo, label='Campo Direto')\n",
    "plt.xlim(0, 1.0)  # primeiros 2s, por exemplo\n",
    "plt.legend()\n",
    "plt.xlabel('Tempo [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53285634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- (b) 1ª Reflexão ---------\n",
    "t2 = distancia_recetor_S1 / c  # Tempo de atraso em segundos\n",
    "m2 = int(t2 * Fs)  # Número de amostras de atraso\n",
    "a2 = (1-a[0]) * (1/distancia_recetor_S1)  # ganho (coeficiente absorção * atenuação)\n",
    "\n",
    "# ABKS E BKS\n",
    "aks = [1]\n",
    "bks = np.zeros(m2 + 1)\n",
    "bks[m2] = a2\n",
    "campo = ss.lfilter(bks, aks, audio[:,0]) # Teve que ser mono para não dar erro\n",
    "\n",
    "display(Audio(campo[:10*Fs], rate=Fs))\n",
    "#plt.plot(campo)\n",
    "#plt.xlim(0, 3*Fs)\n",
    "t = np.arange(len(campo)) / Fs \n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(t, campo, label='Campo Direto')\n",
    "plt.xlim(0, 1.0)  # primeiros 2s, por exemplo\n",
    "plt.legend()\n",
    "plt.xlabel('Tempo [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- 2ª Reflexão ---------\n",
    "t3 = distancia_recetor_S2 / c  # Tempo de atraso em segundos\n",
    "m3 = int(t3 * Fs)  # Número de amostras de atraso\n",
    "a3 = (1-a[1]) * (1/distancia_recetor_S2)  # ganho (coeficiente absorção * atenuação)\n",
    "\n",
    "# ABKS E BKS\n",
    "aks = [1]\n",
    "bks = np.zeros(m3 + 1)\n",
    "bks[m3] = a3\n",
    "campo = ss.lfilter(bks, aks, audio[:,0]) # Teve que ser mono para não dar erro\n",
    "\n",
    "\n",
    "display(Audio(campo[:10*Fs], rate=Fs))\n",
    "#plt.plot(campo)\n",
    "#plt.xlim(0, 3*Fs)\n",
    "t = np.arange(len(campo)) / Fs \n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(t, campo, label='Campo Direto')\n",
    "plt.xlim(0, 1.0)  # primeiros 2s, por exemplo\n",
    "plt.legend()\n",
    "plt.xlabel('Tempo [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7733c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- (c) Campo Reverberante ---------\n",
    "\n",
    "# Para se observar o RT60, aplica-se a um impulso\n",
    "impulso = np.zeros(20 * Fs)\n",
    "impulso[0] = 1\n",
    "\n",
    "teste1 = reverb(impulso, 0.5)\n",
    "teste2 = reverb(impulso, 2)\n",
    "teste3 = reverb(impulso, 10)\n",
    "    \n",
    "t = np.arange(len(impulso)) / Fs \n",
    "plt.stem(t, teste1, label='RT60 = 0.5 s')\n",
    "plt.xlim(0, 11)  # primeiros 11s, por exemplo\n",
    "plt.legend()\n",
    "plt.xlabel('Tempo [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.stem(t, teste2, label='RT60 = 2 s')\n",
    "plt.xlim(0, 11)  # primeiros 11s, por exemplo\n",
    "plt.legend()\n",
    "plt.xlabel('Tempo [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.stem(t, teste3, label='RT60 = 10 s')\n",
    "plt.xlim(0, 11)  # primeiros 11s, por exemplo\n",
    "plt.legend()\n",
    "plt.xlabel('Tempo [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc37eb8a",
   "metadata": {},
   "source": [
    "##### Exercício 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d119978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Campo Binaural ---------\n",
    "alfas = [0, 0.5, 0.8, 1]\n",
    "RT60s = [0, 0.5, 2, 10]\n",
    "\n",
    "audios = [\n",
    "    audio1,  \n",
    "    audio2,  \n",
    "    audio3,  \n",
    "    audio4, \n",
    "    audio5,  \n",
    "    audio6,  \n",
    "    audio7   \n",
    "]\n",
    "\n",
    "fontes = [\n",
    "    fonte1,\n",
    "    fonte2,\n",
    "    fonte3,\n",
    "    fonte4,\n",
    "    fonte5,\n",
    "    fonte6,\n",
    "    fonte7\n",
    "]\n",
    "\n",
    "\n",
    "def calcular_angulos(fonte):\n",
    "    fonte = np.asarray(fonte, dtype=float)\n",
    "    recetor = np.asarray(recetorPos, dtype=float)\n",
    "\n",
    "    # vetor da fonte para o recetor\n",
    "    v = recetor - fonte\n",
    "    dx, dy = v\n",
    "\n",
    "    # ângulo em graus (intervalo [-180, 180])\n",
    "    angulo = np.degrees(np.arctan2(dy, dx))\n",
    "\n",
    "    # forçar múltiplos de 5 graus\n",
    "    angulo = 5 * np.round(angulo / 5)\n",
    "\n",
    "    return angulo\n",
    "\n",
    "\n",
    "def filtros_em_fonte(fonte, alfa, RT60, posFonte):\n",
    "    distancia_recetor_fonte = np.sqrt((np.abs(recetorPos[0])-np.abs(posFonte[0]))**2 + (np.abs(recetorPos[1])-np.abs(posFonte[1]))**2)  # Distância entre fonte e recetor\n",
    "    distancia_recetor_S1 = distancia_reflexao(posFonte, 'horizontal')  # Distância entre recetor e S1\n",
    "    distancia_recetor_S2 = distancia_reflexao(posFonte, 'vertical')  # Distância entre recetor e S2\n",
    "\n",
    "    # --------- Campo Direto ---------\n",
    "    t1 = distancia_recetor_fonte / c  # Tempo de atraso em segundos\n",
    "    m1 = int(t1 * Fs)  # Número de amostras de atraso\n",
    "    a1 = (1/distancia_recetor_fonte) # ganho (atenuação)\n",
    "\n",
    "    # ABKS E BKS\n",
    "    aks = [1]\n",
    "    bks = np.zeros(m1 + 1)\n",
    "    bks[m1] = a1\n",
    "    campoDireto = ss.lfilter(bks, aks, fonte) # Teve que ser mono para não dar erro\n",
    "\n",
    "    # --------- 1º Reflexão ---------\n",
    "    t2 = distancia_recetor_S1 / c  # Tempo de atraso em segundos\n",
    "    m2 = int(t2 * Fs)  # Número de amostras de atraso\n",
    "    a2 = (1-alfa[0]) * (1/distancia_recetor_S1)  # ganho (coeficiente absorção * atenuação)\n",
    "\n",
    "    # ABKS E BKS\n",
    "    aks = [1]\n",
    "    bks = np.zeros(m2 + 1)\n",
    "    bks[m2] = a2\n",
    "    campoReflexao1 = ss.lfilter(bks, aks, fonte) # Teve que ser mono para não dar erro\n",
    "\n",
    "    # --------- 2ª Reflexão ---------\n",
    "    t3 = distancia_recetor_S2 / c  # Tempo de atraso em segundos\n",
    "    m3 = int(t3 * Fs)  # Número de amostras de atraso\n",
    "    a3 = (1-alfa[1]) * (1/distancia_recetor_S2)  # ganho (coeficiente absorção * atenuação)\n",
    "\n",
    "    # ABKS E BKS\n",
    "    aks = [1]\n",
    "    bks = np.zeros(m3 + 1)\n",
    "    bks[m3] = a3\n",
    "    campoReflexao2 = ss.lfilter(bks, aks, fonte) # Teve que ser mono para não dar erro\n",
    "\n",
    "        \n",
    "    campo = campoDireto + campoReflexao1 + campoReflexao2\n",
    "    campoReverberado = reverb(campoReflexao1 + campoReflexao2, RT60)\n",
    "    campoTotal = campo + campoReverberado\n",
    "    return campoTotal\n",
    "\n",
    "\n",
    "def aplicar_hrtf(campo, angulo):\n",
    "    if np.abs(angulo) == 0:\n",
    "        hrtfData = np.fromfile('compact/elev0/H0e000a.dat',dtype='short')\n",
    "    elif np.abs(angulo) < 100:\n",
    "        hrtfData = np.fromfile(f'compact/elev0/H0e0{int(np.abs(angulo))}a.dat',dtype='short')\n",
    "    else:\n",
    "        hrtfData = np.fromfile(f'compact/elev0/H0e{int(np.abs(angulo))}a.dat',dtype='short')\n",
    "\n",
    "    leftimp00= hrtfData[0::2]\n",
    "    rightimp00 = hrtfData[1::2]    \n",
    "\n",
    "    if(angulo < 0):\n",
    "        rightimp00, leftimp00 = leftimp00, rightimp00\n",
    "\n",
    "    lchannel00=np.convolve(leftimp00,campo*1.0)\n",
    "    rchannel00=np.convolve(rightimp00,campo*1.0)\n",
    "    newData00 = np.zeros((len(lchannel00),2))\n",
    "    newData00[:,0] = lchannel00/np.max(np.abs(lchannel00))*2**15\n",
    "    newData00[:,1] = rchannel00/np.max(np.abs(rchannel00))*2**15\n",
    "    return newData00\n",
    "    \n",
    "\n",
    "for alfa in alfas:\n",
    "    soma = 0\n",
    "    for i in range(len(audios)):\n",
    "        fonte = audios[i]\n",
    "        posFonte = fontes[i]\n",
    "        angulo = calcular_angulos(posFonte)\n",
    "        campoTotal = filtros_em_fonte(fonte, [alfa, alfa], 0.2 , posFonte)\n",
    "        newData = aplicar_hrtf(campoTotal, angulo)\n",
    "        soma += newData\n",
    "    \n",
    "    soma = soma / np.max(np.abs(soma)) * (2**15 - 1)\n",
    "    wav.write(f\"CampoBinaural_alfa_{alfa}.wav\", Fs, soma.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6595e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binaural com Reverberação\n",
    "\n",
    "for rt60 in RT60s:\n",
    "    soma = 0\n",
    "    for i in range(len(audios)):\n",
    "        fonte = audios[i]\n",
    "        posFonte = fontes[i]\n",
    "        angulo = calcular_angulos(posFonte)\n",
    "        campoTotal = filtros_em_fonte(fonte, a, rt60, posFonte)\n",
    "        newData = aplicar_hrtf(campoTotal, angulo)\n",
    "        soma += newData\n",
    "\n",
    "    soma = soma / np.max(np.abs(soma)) * (2**15 - 1)\n",
    "    wav.write(f\"CampoBinaural_RT60_{rt60}.wav\", Fs, soma.astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78251a",
   "metadata": {},
   "source": [
    "##### Exercício 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d310a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- (1) Codificação Ambisónica ---------\n",
    "# Função para calcular o ângulo entre a fonte e o recetor\n",
    "def angulo(posFonte, recetorPos):\n",
    "    dx = posFonte[0] - recetorPos[0]\n",
    "    dy = posFonte[1] - recetorPos[1]\n",
    "    a = np.arctan2(dy, dx)  # radianos\n",
    "    return a\n",
    "\n",
    "# Função para codificação ambisónica de ordem 1 (sem Z porque trabalhamos em 2D)\n",
    "def ambisonic_encode(S, angulo):\n",
    "    W = S * (1/np.sqrt(2))\n",
    "    X = S * np.cos(angulo)\n",
    "    Y = S * np.sin(angulo)\n",
    "    return W, X, Y\n",
    "\n",
    "W = np.zeros_like(audio, dtype=np.float32)\n",
    "X = np.zeros_like(audio, dtype=np.float32)\n",
    "Y = np.zeros_like(audio, dtype=np.float32)\n",
    "\n",
    "for i in range(len(fontes)):\n",
    "    fonte = fontes[i]\n",
    "    audio = audios[i]\n",
    "\n",
    "    # Campo direto ambisónico\n",
    "    angulo_direto = angulo(fonte, recetorPos)\n",
    "    W1, X1, Y1 = ambisonic_encode(audio, angulo_direto)\n",
    "\n",
    "    # 1ª reflexão ambisónica\n",
    "    angulo_reflexao1 = angulo((-fonte[0], fonte[1]), recetorPos)  # reflexão na parede vertical\n",
    "    W2, X2, Y2 = ambisonic_encode(audio, angulo_reflexao1)\n",
    "\n",
    "    # 2ª reflexão ambisónica\n",
    "    angulo_reflexao2 = angulo((fonte[0], -fonte[1]), recetorPos)  # reflexão na parede horizontal\n",
    "    W3, X3, Y3 = ambisonic_encode(audio, angulo_reflexao2)\n",
    "\n",
    "    # Soma dos componentes ambisónicos\n",
    "    W_aux = W1 + W2 + W3\n",
    "    X_aux = X1 + X2 + X3\n",
    "    Y_aux = Y1 + Y2 + Y3\n",
    "\n",
    "    W += W_aux\n",
    "    X += X_aux\n",
    "    Y += Y_aux\n",
    "\n",
    "# Normalização dos sinais ambisónicos\n",
    "max_val = max(np.max(np.abs(W)),np.max(np.abs(X)),np.max(np.abs(Y)))\n",
    "W = W /max_val\n",
    "X = X /max_val\n",
    "Y = Y /max_val\n",
    "\n",
    "ambisonic_WXY = np.column_stack((W, X, Y))\n",
    "ambisonic_WXY = ambisonic_WXY / np.max(np.abs(ambisonic_WXY))\n",
    "ambisonic_WXY = (ambisonic_WXY * (2**15-1)).astype(np.int16)\n",
    "# Gravação dos sinais ambisónicos \n",
    "wav.write(\"Ambisonic.wav\", Fs, ambisonic_WXY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e47b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- (2) Definir geometria de localização dos altifalantes ---------\n",
    "def gerar_altifalantes_circulares(cx, cy, raio):\n",
    "    coordenadas = []\n",
    "    for i in range(8):\n",
    "        a = np.pi/2 + 2 * np.pi * i / 8  # Começa no π/2 (segundo a imagem do slide 41)\n",
    "        x = cx + raio * np.cos(a)\n",
    "        y = cy + raio * np.sin(a)\n",
    "        coordenadas.append((round(x, 2), round(y, 2)))\n",
    "    return coordenadas\n",
    "\n",
    "centro = (10, 4)\n",
    "raio = 2\n",
    "\n",
    "altifalantes = gerar_altifalantes_circulares(centro[0], centro[1], raio)\n",
    "#for i, coord in enumerate(altifalantes, start=1):\n",
    "#    print(f\"S{i} = {coord}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- (3) Criação de um microfone ---------\n",
    "p = 0.5 \n",
    "microfone_pos = recetorPos  # Posição do microfone (x, y)\n",
    "def microfone_ambisonico(angulo, p, W, X, Y):\n",
    "    M = p * np.sqrt(2) * W  + (1 - p) * (np.cos(angulo) * X + np.sin(angulo) * Y)\n",
    "    return M\n",
    "\n",
    "direcoes = []\n",
    "for alt in altifalantes:\n",
    "    dx = alt[0] - microfone_pos[0]\n",
    "    dy = alt[1] - microfone_pos[1]\n",
    "    mag = np.sqrt(dx**2 + dy**2)\n",
    "    dir_normalizada = (dx/mag, dy/mag)\n",
    "    direcoes.append(dir_normalizada)\n",
    "\n",
    "# Exemplo de visualização\n",
    "for i, d in enumerate(direcoes, start=1):\n",
    "    print(f\"Direcao para S{i}: {d}, p={p}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
