{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c345f75",
   "metadata": {},
   "source": [
    "# Trabalho prático 2\n",
    "### Processamento de Sinais Multimédia\n",
    "####  Alunos: Diana Oliveira 52651; Beatriz Jesus 52749; Guilherme Cavalcanti 53077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560bbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal as ss\n",
    "import scipy.io.wavfile as wav \n",
    "from IPython.display import Audio, display "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81371bd6",
   "metadata": {},
   "source": [
    "##### Exercício 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8772360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Parâmetros Globais ---------\n",
    "Fs = 48000  # Frequência de amostragem\n",
    "temperatura = 20  # Temperatura em graus Celsius\n",
    "recetor = (10,4) # Coordenadas do recetor (x,y) em metros\n",
    "fonte = (8,7) # Coordenadas da fonte (x,y) em metros\n",
    "S1 = (8,13) # reflexão da parede horizontal absorção=0.5\n",
    "S2 = (-7,7) # reflexão da parede vertical absorção=0.3\n",
    "a = [0.5, 0.3]  # Coeficientes de absorção das paredes [parede vertical, parede horizontal]\n",
    "c = 331.5 * np.sqrt(1 + temperatura/273) # Velocidade do som no ar em m/s \n",
    "\n",
    "# --------- MUTES ---------\n",
    "#campo_direto_mute = False\n",
    "mute1 = False\n",
    "\n",
    "# --------- Converter Aúdio ---------\n",
    "# O aúdio utilizado já tem 16 bits mas fs=44100 Hz --> Tem que converter para Fs=48000 Hz\n",
    "fs_audio_org, audio_org = wav.read(\"Borderline_UnmasteredWAV.wav\")\n",
    "\n",
    "num_samples_new = int(len(audio_org) * Fs / fs_audio_org) # Número de amostras do áudio novo\n",
    "audio_resampled = ss.resample(audio_org, num_samples_new, axis=0) # Resample do áudio para a nova frequência de amostragem \n",
    "audio_resampled = audio_resampled.astype(np.int16) # Converter para 16 bits, senão fica a 64 bits\n",
    "\n",
    "wav.write(\"AudioConvertido.wav\", Fs, audio_resampled)\n",
    "\n",
    "# --------- Ler Aúdio Convertido  ---------\n",
    "_ , audio = wav.read(\"AudioConvertido.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464150bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------(d) Campo total = Campo direto + Primeiras reflexões + Campo Reverberante ---------\n",
    "distancia_recetor_fonte = np.sqrt((np.abs(recetor[0])-np.abs(fonte[0]))**2 + (np.abs(recetor[1])-np.abs(fonte[1]))**2)  # Distância entre fonte e recetor\n",
    "distancia_recetor_S1 = np.sqrt((np.abs(recetor[0])-np.abs(S1[0]))**2 + (np.abs(recetor[1])-np.abs(S1[1]))**2)  # Distância entre recetor e S1\n",
    "distancia_recetor_S2 = np.sqrt((np.abs(recetor[0])-np.abs(S2[0]))**2 + (np.abs(recetor[1])-np.abs(S2[1]))**2)  # Distância entre recetor e S2\n",
    "\n",
    "# --------- Campo Direto ---------\n",
    "t1 = distancia_recetor_fonte / c  # Tempo de atraso em segundos\n",
    "m1 = int(t1 * Fs)  # Número de amostras de atraso\n",
    "a1 = audio[:,0] * (1/distancia_recetor_fonte) # ganho (atenuação)\n",
    "\n",
    "# --------- 1º Reflexão ---------\n",
    "t2 = distancia_recetor_S1 / c  # Tempo de atraso em segundos\n",
    "m2 = int(t2 * Fs)  # Número de amostras de atraso\n",
    "a2 =  audio[:,0] * (1-a[0]) * (1/distancia_recetor_S1)  # ganho (coeficiente absorção * atenuação)\n",
    "\n",
    "# --------- 2º Reflexão ---------\n",
    "t3 = distancia_recetor_S2 / c  # Tempo de atraso em segundos\n",
    "m3 = int(t3 * Fs)  # Número de amostras de atraso\n",
    "a3 = audio[:,0] * (1-a[1]) * (1/distancia_recetor_S2) # ganho (coeficiente absorção * atenuação pela distância)\n",
    "\n",
    "\n",
    "# Aplicar o atraso a cada um dos audios\n",
    "\n",
    "atraso1 = np.zeros((m1))\n",
    "a1 = np.concatenate((atraso1, a1), axis=0)# ganho do campo direto\n",
    "\n",
    "atraso2 = np.zeros((m2))    \n",
    "a2 = np.concatenate((atraso2, a2), axis=0) # ganho da 1ª reflexão\n",
    "\n",
    "atraso3 = np.zeros((m3))\n",
    "a3 = np.concatenate((atraso3, a3), axis=0)# ganho da 2ª reflexão\n",
    "\n",
    "# Determinar o tamanho máximo\n",
    "max_len = max(len(a1), len(a2), len(a3))\n",
    "\n",
    "# Preencher zeros no final de cada array para igualar tamanhos\n",
    "a1 = np.pad(a1, (0, max_len - len(a1)), mode='constant')\n",
    "a2 = np.pad(a2, (0, max_len - len(a2)), mode='constant')\n",
    "a3 = np.pad(a3, (0, max_len - len(a3)), mode='constant')\n",
    "\n",
    "\n",
    "campo = a1 + a2 + a3 #campo direto, 1ª e 2ª reflexão\n",
    "\n",
    "\n",
    "\n",
    "# --------- RT60 ---------\n",
    "\n",
    "mi = int(0.03 * Fs)   # atraso de 30 milissegundos \n",
    "\n",
    "def reverb(campo, RT60):\n",
    "    ganho = 10**((-3 * mi) / (RT60)) # 20*log10(g) / (m*T) = -60 / Tr  => log10(g) = -3*m*T / Tr , onde tr é rt60 e o T é o peirodo de amostragem 1/Fs\n",
    "    bks = [1]\n",
    "    aks = np.zeros(mi + 1)\n",
    "    aks[0] = 1\n",
    "    aks[-1] = -ganho\n",
    "    return ss.lfilter(bks, aks, campo)\n",
    "\n",
    "\n",
    "\n",
    "# Aplicar a reverberação para diferentes valores de RT60\n",
    "#campo0  = reverb(campo, 0)\n",
    "campo05 = reverb(campo, 0.5)\n",
    "campo2  = reverb(campo, 2)\n",
    "campo10 = reverb(campo, 10)\n",
    "    \n",
    "\n",
    "# Normalizar os sinais\n",
    "#campo_total_0 = campo0/np.max(np.abs(campo0))\n",
    "campo_total_05 = campo05/np.max(np.abs(campo05))\n",
    "campo_total_2 = campo2/np.max(np.abs(campo2))\n",
    "campo_total_10 = campo10/np.max(np.abs(campo10))\n",
    "\n",
    "\n",
    "# --------- Gravar e Reproduzir 10 segundos do Aúdio ---------\n",
    "filename_exercício1 = [\"Exercício1_RT60_0.wav\", \"Exercício1_RT60_0.5.wav\", \"Exercício1_RT60_2.wav\", \"Exercício1_RT60_10.wav\"]\n",
    "#wav.write(filename_exercício1[0], Fs, (campo_total_0 * 32767).astype(np.int16))\n",
    "wav.write(filename_exercício1[1], Fs,  (campo_total_05).astype(np.int16))\n",
    "wav.write(filename_exercício1[2], Fs,  (campo_total_2).astype(np.int16))\n",
    "wav.write(filename_exercício1[3], Fs,  (campo_total_10).astype(np.int16))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Aúdio Original\")\n",
    "display(Audio(\"AudioConvertido.wav\", rate=Fs))\n",
    "#print(\"RT60 = 0s\")\n",
    "#display(Audio(campo_total_0[:10*Fs], rate=Fs))\n",
    "print(\"RT60 = 0.5s\")\n",
    "display(Audio(campo_total_05[:10*Fs], rate=Fs))\n",
    "print(\"RT60 = 2s\")\n",
    "display(Audio(campo_total_2[:10*Fs], rate=Fs))\n",
    "print(\"RT60 = 10s\")\n",
    "display(Audio(campo_total_10[:10*Fs], rate=Fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- (c) Campo Reverberante ---------\n",
    "m = int(0.03 * Fs)   # atraso de 30 milissegundos \n",
    "\n",
    "def reverb(campo, RT60):\n",
    "    ganho = 10**((-3 * m* (1/Fs)) / (RT60)) # 20*log10(g) / (m*T) = -60 / Tr  => log10(g) = -3*m*T / Tr , onde tr é rt60 e o T é o peirodo de amostragem 1/Fs\n",
    "    bks = [1]\n",
    "    aks = np.zeros(m + 1)\n",
    "    aks[0] = 1\n",
    "    aks[-1] = -ganho\n",
    "    return ss.lfilter(bks, aks, campo)\n",
    "\n",
    "\n",
    "# Aplicar a reverberação para diferentes valores de RT60\n",
    "#Como a reverberaçao esta a ser aplicada num audio, a reverberaçao nao acaba\n",
    "#campo05 = reverb(audio[:,0], 0.5)\n",
    "#campo2  = reverb(audio[:,0], 2)\n",
    "#campo10 = reverb(audio[:,0], 10)\n",
    "\n",
    "# Para se observar o RT60, aplica-se a um impulso\n",
    "impulso = np.zeros(20 * Fs)\n",
    "impulso[0] = 1\n",
    "\n",
    "teste1 = reverb(impulso, 0.5)\n",
    "teste2 = reverb(impulso, 2)\n",
    "teste3 = reverb(impulso, 10)\n",
    "    \n",
    "t = np.arange(len(impulso)) / Fs \n",
    "plt.plot(t, teste1, label='RT60 = 0.5 s', color='blue')\n",
    "plt.xlim(0, 11)  # primeiros 11s, por exemplo\n",
    "plt.legend()\n",
    "plt.xlabel('Tempo [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(t, teste2, label='RT60 = 2 s', color='orange')\n",
    "plt.xlim(0, 11)  # primeiros 11s, por exemplo\n",
    "plt.legend()\n",
    "plt.xlabel('Tempo [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(t, teste3, label='RT60 = 10 s', color='green')\n",
    "plt.xlim(0, 11)  # primeiros 11s, por exemplo\n",
    "plt.legend()\n",
    "plt.xlabel('Tempo [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f37fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- (a) Campo Direto ---------\n",
    "t1 = distancia_recetor_fonte / c  # Tempo de atraso em segundos\n",
    "m1 = int(t1 * Fs)  # Número de amostras de atraso\n",
    "a1 = (1/distancia_recetor_fonte) # ganho (atenuação)\n",
    "# ABKS E BKS\n",
    "aks = 1\n",
    "bks = np.zeros(m1 + 1)\n",
    "bks[m1] = a1\n",
    "campo = ss.lfilter(bks, aks, audio[:,0]) # Teve que ser mono para não dar erro\n",
    "\n",
    "\n",
    "display(Audio(campo[:10*Fs], rate=Fs))\n",
    "#plt.plot(campo)\n",
    "#plt.xlim(0, 3*Fs)\n",
    "t = np.arange(len(campo)) / Fs \n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(t, campo, label='Campo Direto')\n",
    "plt.xlim(0, 1.0)  # primeiros 2s, por exemplo\n",
    "plt.legend()\n",
    "plt.xlabel('Tempo [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53285634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- (b) 1ª Reflexão ---------\n",
    "t2 = distancia_recetor_S1 / c  # Tempo de atraso em segundos\n",
    "m2 = int(t2 * Fs)  # Número de amostras de atraso\n",
    "a2 = (1-a[0]) * (1/distancia_recetor_S1)  # ganho (coeficiente absorção * atenuação)\n",
    "\n",
    "# ABKS E BKS\n",
    "aks = [1]\n",
    "bks = np.zeros(m2 + 1)\n",
    "bks[m2] = a2\n",
    "campo = ss.lfilter(bks, aks, audio[:,0]) # Teve que ser mono para não dar erro\n",
    "\n",
    "display(Audio(campo[:10*Fs], rate=Fs))\n",
    "#plt.plot(campo)\n",
    "#plt.xlim(0, 3*Fs)\n",
    "t = np.arange(len(campo)) / Fs \n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(t, campo, label='Campo Direto')\n",
    "plt.xlim(0, 1.0)  # primeiros 2s, por exemplo\n",
    "plt.legend()\n",
    "plt.xlabel('Tempo [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- 2ª Reflexão ---------\n",
    "t3 = distancia_recetor_S2 / c  # Tempo de atraso em segundos\n",
    "m3 = int(t3 * Fs)  # Número de amostras de atraso\n",
    "a3 = (1-a[1]) * (1/distancia_recetor_S2)  # ganho (coeficiente absorção * atenuação)\n",
    "\n",
    "# ABKS E BKS\n",
    "aks = [1]\n",
    "bks = np.zeros(m3 + 1)\n",
    "bks[m3] = a3\n",
    "campo = ss.lfilter(bks, aks, audio[:,0]) # Teve que ser mono para não dar erro\n",
    "\n",
    "\n",
    "display(Audio(campo[:10*Fs], rate=Fs))\n",
    "#plt.plot(campo)\n",
    "#plt.xlim(0, 3*Fs)\n",
    "t = np.arange(len(campo)) / Fs \n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(t, campo, label='Campo Direto')\n",
    "plt.xlim(0, 1.0)  # primeiros 2s, por exemplo\n",
    "plt.legend()\n",
    "plt.xlabel('Tempo [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
